---
title: "Chapter 5 - Multivariate Linear Models"
output: html_notebook
---

# Introduction

In large data sets, every pair of variables has a statistically discernible non-zero correlation. Most of these relationships are non-causal. Multivariate regression can help us examine causal relatinoships by:

1. Statistical control for confounders. A counfound is a variable that may be correlated with another variable of interest.
2. Multiple Cuasation. A phenomonen may really arise from multiple causes.
3. Interactions. Even when variables are completely uncorrelated, the importance of each may still depend upon the other.

# Spurious association example

In this example, we'll examine `divorce rate`, `median age at marriage`, `marriage rate` in a data set where each observation is a state. Lets begin by looking at their relationships with divorce rate individually first.
```{r}
library(rethinking)
library(tidyverse)
rstan_options(auto_write = TRUE)

data(WaffleDivorce)
d <- WaffleDivorce
d %>% 
  skimr::skim()
```



```{r}
# Standardize the predictor `median age at marriage`
d$MedianAgeMarriage.s <- (d$MedianAgeMarriage - mean(d$MedianAgeMarriage)) / sd(d$MedianAgeMarriage)

# Fit divorce rate 
m5.1 <- rethinking::map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bA * MedianAgeMarriage.s,
    a ~ dnorm(10, 10),
    bA ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)), 
  data = d)

# Standardize the predictor `Marriage`
d$Marriage.s <- (d$Marriage - mean(d$Marriage)) / sd(d$Marriage)

# Fit it's relationship with divorce rate
m5.2 <- rethinking::map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bR * Marriage.s,
    a ~ dnorm(10, 10),
    bR ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)),
  data = d)

par(mfrow=c(1,2)) 
m5.1 %>% 
  precis %>% 
  plot(main="Median age at marriage")
m5.2 %>% 
  precis %>% 
  plot(main = "Marriage rate")
```

The regression above shows that each additional standard deviation of delay in marriage (1.24 years) predicts a decrease of about one divorce per thousand adults, withh an 89% interval from -1.4 to -0.7. It also shows an increase of .6 divorces for every additional standard deviation of marriage rate (3.8). However, merely comparing paramter means between different bivariate regressions tells us very little. Both predictors could provide independent value, be redundant, or eliminate the value of the other. 

What we should do is model them together in a multivariate model. We want to know, `What is the predictive value of a variable once I already know all of the other predictor variables.`

```{r}
m5.3 <- rethinking::map(
  alist(
    Divorce ~ dnorm(mu, sigma),
    mu <- a + bR*Marriage.s + bA*MedianAgeMarriage.s,
    a ~ dnorm(10, 10),
    bR ~ dnorm(0, 1),
    bA ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)),
  data = d)

m5.3 %>% 
  precis %>% 
  plot
```

The posterior mean for marraige rate, `bR`, is now close to zero. Once we know median age at marriage for a state, there is little or no additional predictive power in also knowing the rate of marriage in that State.

# Plotting multivariate posteriors

Multivariate regressions can get complicated. To interrogate them better, we can use plots to our advantage. There are some plot types to interpret models.

1. _Predictor residual plots_: Show the outcome against residual predictor values.
2. _Counterfactual plots_: Show implied predictions for made up data.
3. _Posterior prediction plots_: Model based predictions against raw data.

## Predictor residual plots

A predictor variable residual is the average prediction error when we use all of the other predictor variables to model a predictor of interest. This allows us to visualize the bivariate relationship between the predictor and the outcome while "controlling" for all of the other predictor variables.

```{r}
# Model marriage as a function of Median Marriage Age
m5.4 <- rethinking::map(
  alist(
    Marriage.s ~ dnorm(mu, sigma),
    mu <- a + b*MedianAgeMarriage.s,
    a ~ dnorm(0, 10),
    b ~ dnorm(0, 1),
    sigma ~ dunif(0, 10)),
  data = d)

# Compute residuals
mu.hat <- coef(m5.4)['a'] + coef(m5.4)['b']*d$MedianAgeMarriage.s
m.resid <- d$Marriage.s - mu.hat

# Generate predictor residual plot
data_frame(
  divorce_rate = d$MedianAgeMarriage.s,
  marriage_rate = m.resid
) %>% 
  ggplot(aes(marriage_rate, divorce_rate)) +
    #geom_point(shape=1, size=3) +
    geom_point(colour="steelblue", size=3, alpha=I(1/3)) +
    geom_smooth(method=lm, formula = y ~ poly(x, 1), colour="black") +
    geom_vline(xintercept=0, linetype=2) +
    theme_bw() + theme_empty() +
    ggtitle("Predictor residual plot") +
    xlab("Marriage Rate Residuals") + ylab("Divorce Rate") + 
    annotate("text", x=-.25, y=3, label = "Younger") +
    annotate("text", x=.2, y=3, label = "Older")

```

Above, we plot the residuals from using median age at marriage to predict marriage rate against our outcome of interest. This plot displays the linear relationship between `divorce` and `marriage rates`, having statistically "controlled" for `median age of marriage`. Recall that multiple linear regression models measure the remaining association of each predictor with the outcome. By computing the predictor residual plots you perform those calculations yourself. 

## Counterfactual plot


















